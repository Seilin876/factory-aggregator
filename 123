import os
import sys
import pandas as pd
import configparser
import logging
from datetime import datetime
import glob
import re
from openpyxl.styles import PatternFill, Border, Side, Alignment, Font

# Initialize logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def create_summary_dashboard(writer, df, date_str):
    """
    Creates a 'Summary_Dashboard' sheet.
    Top Section: Failure Mode Analysis Summary (Global List).
    Bottom Section: Detailed per-line dashboard (Original Format).
    """
    workbook = writer.book
    sheet_name = 'Summary_Dashboard'
    
    # --- 1. Data Pre-processing ---
    
    # A. Convert critical columns to Numeric
    # Added 'dB(A)' for Failure Mode #5
    numeric_cols = ['index1', 'index1_limit', 'index2', 'index2_limit', 'RPM', 'RPM_Low', 'dB(A)']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        else:
            df[col] = 0

    # B. Define Basic Conditions
    cond_rotating = (df['RPM'] != 0)
    cond_idx1_high = (df['index1'] > df['Index1_Limit'])
    cond_idx2_high = (df['index2'] > df['Index2_Limit'])
    cond_out_of_control = (df['RPM'] > df['RPM_Low']) + (df['RPM'] > 10000)
    cond_no_rotate = (df['RPM'] == 0)

    # --- 2. Calculate Final Categories ---

    df['is_fail'] = df['Total_Result'].apply(lambda x: 0 if str(x).strip().upper() == 'OK' else 1)

    df['calc_noise'] = (
        ((cond_idx1_high) & (~cond_idx2_high) & (cond_rotating)).astype(int) +
        ((cond_idx2_high) & (~cond_idx1_high) & (cond_rotating)).astype(int) +
        ((cond_idx1_high) & (cond_idx2_high) & (cond_rotating)).astype(int) +
        df.apply(lambda row: 1 if str(row.get('Intelligent_Control','')).strip().upper() == 'OK' 
                 and str(row.get('Total_Result','')).strip().upper() != 'OK' else 0, axis=1)
    )

    df['calc_only_idx1'] = ((cond_idx1_high) & (~cond_idx2_high) & (cond_rotating)).astype(int)
    df['calc_only_idx2'] = ((cond_idx2_high) & (~cond_idx1_high) & (cond_rotating)).astype(int)
    df['calc_both_idx'] = ((cond_idx1_high) & (cond_idx2_high) & (cond_rotating)).astype(int)
    df['calc_spec_fail'] = df.apply(lambda row: 1 if str(row.get('Intelligent_Control','')).strip().upper() == 'OK' 
                                    and str(row.get('Total_Result','')).strip().upper() != 'OK' else 0, axis=1)
    
    df['calc_out_control'] = cond_out_of_control.astype(int)
    df['calc_no_rotate'] = cond_no_rotate.astype(int)
    df['calc_rpm_ng'] = ((cond_out_of_control) | (cond_no_rotate)).astype(int)

    df['calc_pause'] = df['Model_Name'].apply(lambda x: 1 if 'pauseorfreerun' in str(x).lower().replace(" ", "") else 0)
    df['calc_no_barcode'] = df['Barcode'].apply(lambda x: 1 if pd.isna(x) or str(x).strip() == '' else 0)
    df['calc_others'] = ((df['calc_pause'] == 1) | (df['calc_no_barcode'] == 1)).astype(int)


    # --- 3. Logic Analysis Phase (Pre-calculation for Summary Board) ---
    
    lines = sorted(df['Line_Name'].unique())
    
    # Dictionary to store detected locations for each mode
    # Format: { 'Mode Name': ['Line1-Station1', 'Line2-Station3'] }
    detected_failures = {
        'Carrier Abnormal': [],
        'Test Pin Abnormal': [],
        'Mic Position Variant': [],
        'Mic Cable Abnormal': [],
        'Isolation Box Abnormal': [],
        'Check Audio File': []
    }

    for line in lines:
        line_df = df[df['Line_Name'] == line]
        stations = sorted(line_df['Device_ID'].unique())
        
        # Helper: Calculate stats for this line
        st_stats = {}
        for st in stations:
            st_data = line_df[line_df['Device_ID'] == st]
            total = len(st_data)
            
            rpm_fail_count = st_data['calc_rpm_ng'].sum()
            other_fail_count = st_data['calc_others'].sum()
            
            rpm_rate = (rpm_fail_count / total) if total > 0 else 0
            other_rate = (other_fail_count / total) if total > 0 else 0
            
            idx1_mean = st_data['index1'].mean() if total > 0 else 0
            idx2_mean = st_data['index2'].mean() if total > 0 else 0
            dba_mean = st_data['dB(A)'].mean() if 'dB(A)' in st_data.columns and total > 0 else 0
            
            cable_fail_count = ((st_data['index1'] > 300) | (st_data['index2'] > 300)).sum()
            
            st_stats[st] = {
                'rpm_rate': rpm_rate,
                'other_rate': other_rate,
                'idx1_mean': idx1_mean,
                'idx2_mean': idx2_mean,
                'dba_mean': dba_mean,
                'cable_fail_count': cable_fail_count
            }

        # Logic 1: Carrier Abnormal (Line Level)
        # All stations RPM > 1.5% OR All stations Other > 1.5%
        if stations:
            all_rpm_high = all(st_stats[s]['rpm_rate'] > 0.015 for s in stations)
            all_other_high = all(st_stats[s]['other_rate'] > 0.015 for s in stations)
            if all_rpm_high or all_other_high:
                detected_failures['Carrier Abnormal'].append(f"{line} (All Stations)")

        # Logic 2: Test Pin Abnormal (Station Level)
        # Single Station RPM > 2% OR Other > 2%
        for s in stations:
            if (st_stats[s]['rpm_rate'] > 0.02) or (st_stats[s]['other_rate'] > 0.02):
                detected_failures['Test Pin Abnormal'].append(f"{line}-{s}")

        # Logic 3, 5, 6: Relative Comparison (Needs >1 station)
        if len(stations) > 1:
            for s in stations:
                other_stations = [os for os in stations if os != s]
                
                # Logic 3: Mic Position
                others_idx1_mean = sum(st_stats[os]['idx1_mean'] for os in other_stations) / len(other_stations)
                others_idx2_mean = sum(st_stats[os]['idx2_mean'] for os in other_stations) / len(other_stations)
                
                if (st_stats[s]['idx1_mean'] < others_idx1_mean * 0.8) or (st_stats[s]['idx2_mean'] < others_idx2_mean * 0.8):
                    detected_failures['Mic Position Variant'].append(f"{line}-{s}")

                # Logic 5: Isolation Box
                others_dba_mean = sum(st_stats[os]['dba_mean'] for os in other_stations) / len(other_stations)
                # Only compare if others exist and are non-zero (avoid div/0 or noise)
                if others_dba_mean > 0:
                    if st_stats[s]['dba_mean'] > others_dba_mean * 1.1:
                         detected_failures['Isolation Box Abnormal'].append(f"{line}-{s}")

                # Logic 6: Check Audio
                if (st_stats[s]['idx1_mean'] > others_idx1_mean * 1.3) or (st_stats[s]['idx2_mean'] > others_idx2_mean * 1.3):
                    detected_failures['Check Audio File'].append(f"{line}-{s}")

        # Logic 4: Mic Cable
        for s in stations:
            if st_stats[s]['cable_fail_count'] > 10:
                detected_failures['Mic Cable Abnormal'].append(f"{line}-{s}")


    # --- 4. Dashboard Generation ---
    if sheet_name not in workbook.sheetnames:
        workbook.create_sheet(sheet_name)
    ws = workbook[sheet_name]

    current_row = 1
    
    # Styles
    thin_border = Border(left=Side(style='thin', color='FFFFFF'), right=Side(style='thin', color='FFFFFF'), top=Side(style='thin', color='FFFFFF'), bottom=Side(style='thin', color='FFFFFF'))
    header_font = Font(bold=True)
    center_align = Alignment(horizontal='center', vertical='center')
    
    # Failure Board Styles
    fail_header_fill = PatternFill(start_color='FF6666', end_color='FF6666', fill_type='solid') # Red Header
    fail_header_font = Font(bold=True, color='FFFFFF', size=14)
    fail_row_fill = PatternFill(start_color='FFCCCC', end_color='FFCCCC', fill_type='solid') # Light Red
    fail_row_font = Font(bold=False, color='000000')

    # Line Dashboard Styles (Original)
    fill_g1_main = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid') 
    font_g1_main = Font(bold=True, color='FFFFFF')
    fill_g1_sub = PatternFill(start_color='FFF2CC', end_color='FFF2CC', fill_type='solid') 
    font_sub_default = Font(bold=False, color='000000')

    fill_g2_main = PatternFill(start_color='BDE7FF', end_color='BDE7FF', fill_type='solid')
    font_g2_main = Font(bold=True, color='000000')
    fill_g2_sub = PatternFill(start_color='D1EFFF', end_color='D1EFFF', fill_type='solid')

    fill_g3_main = PatternFill(start_color='A0E8E6', end_color='A0E8E6', fill_type='solid')
    font_g3_main = Font(bold=True, color='000000')
    fill_g3_sub = PatternFill(start_color='C6F1F0', end_color='C6F1F0', fill_type='solid')

    fill_g4_main = PatternFill(start_color='C9F084', end_color='C9F084', fill_type='solid')
    font_g4_main = Font(bold=True, color='000000')
    fill_g4_sub = PatternFill(start_color='E0F6B8', end_color='E0F6B8', fill_type='solid')

    rank_1_fill = PatternFill(start_color='FF5050', end_color='FF5050', fill_type='solid')
    rank_2_fill = PatternFill(start_color='FF7C80', end_color='FF7C80', fill_type='solid')
    rank_3_fill = PatternFill(start_color='FF9999', end_color='FF9999', fill_type='solid')
    rank_4_fill = PatternFill(start_color='FFCCCC', end_color='FFCCCC', fill_type='solid')


    # ==========================================
    # PART A: WRITE FAILURE MODE SUMMARY BOARD
    # ==========================================
    
    # 1. Title
    ws.merge_cells(start_row=current_row, start_column=1, end_row=current_row, end_column=3)
    title_cell = ws.cell(row=current_row, column=1, value=f"Daily Failure Mode Analysis ({date_str})")
    title_cell.font = fail_header_font
    title_cell.fill = fail_header_fill
    title_cell.alignment = center_align
    current_row += 1

    # 2. Headers
    ws.cell(row=current_row, column=1, value="No.").font = Font(bold=True)
    ws.cell(row=current_row, column=2, value="Failure Mode").font = Font(bold=True)
    ws.cell(row=current_row, column=3, value="Detected Locations (Line - Station)").font = Font(bold=True)
    
    for col in range(1, 4):
        c = ws.cell(row=current_row, column=col)
        c.fill = PatternFill(start_color='E0E0E0', end_color='E0E0E0', fill_type='solid') # Grey
        c.border = thin_border
        c.alignment = center_align
    current_row += 1

    # 3. List the 6 Modes
    modes_order = [
        'Carrier Abnormal', 
        'Test Pin Abnormal', 
        'Mic Position Variant', 
        'Mic Cable Abnormal', 
        'Isolation Box Abnormal', 
        'Check Audio File'
    ]

    for idx, mode in enumerate(modes_order, 1):
        # Index
        c1 = ws.cell(row=current_row, column=1, value=idx)
        c1.fill = fail_row_fill
        c1.border = thin_border
        c1.alignment = center_align

        # Mode Name
        c2 = ws.cell(row=current_row, column=2, value=mode)
        c2.fill = fail_row_fill
        c2.border = thin_border
        c2.alignment = Alignment(horizontal='left', vertical='center')

        # Results
        locations = detected_failures.get(mode, [])
        if locations:
            res_str = ", ".join(locations)
            # Highlight text in Red if issues found
            font_res = Font(color='FF0000', bold=True)
        else:
            res_str = "OK"
            font_res = Font(color='008000', bold=True) # Green for OK

        c3 = ws.cell(row=current_row, column=3, value=res_str)
        c3.fill = fail_row_fill
        c3.border = thin_border
        c3.font = font_res
        c3.alignment = Alignment(horizontal='left', vertical='center', wrap_text=True)

        current_row += 1

    current_row += 2 # Add Spacer between Summary Board and Detailed Report


    # ==========================================
    # PART B: WRITE DETAILED PER-LINE DASHBOARD
    # ==========================================
    
    for line in lines:
        line_df = df[df['Line_Name'] == line]
        stations = sorted(line_df['Device_ID'].unique())
        
        # Header: Line Name
        ws.merge_cells(start_row=current_row, start_column=1, end_row=current_row, end_column=len(stations)+2)
        cell = ws.cell(row=current_row, column=1, value=line)
        cell.font = Font(bold=True, size=14, color='FFFFFF')
        cell.fill = fill_g1_main
        cell.alignment = center_align
        current_row += 1

        # Column Headers
        headers = ['Metric', 'Total'] + stations
        for i, h in enumerate(headers):
            c = ws.cell(row=current_row, column=i+1, value=h)
            c.font = Font(bold=True)
            c.fill = PatternFill(start_color='DDDDDD', end_color='DDDDDD', fill_type='solid')
            c.border = thin_border
            c.alignment = center_align
        current_row += 1

        # Metrics Configuration (Original Group 1-4)
        metrics_config = [
            # Group 1: Summary
            ('Total Count',       None,               False, False, 1, False),
            ('Fail Count',        'is_fail',          False, False, 1, False),
            ('Fail Rate',         'is_fail',          True,  False, 1, False),
            ('Noise Rate',        'calc_noise',       True,  False, 1, False),
            ('RPM Fail Rate',     'calc_rpm_ng',      True,  False, 1, False),
            ('Other Fail Rate',   'calc_others',      True,  False, 1, False),
            
            # Group 2: Noise Fail
            ('Noise',             'calc_noise',       False, False, 2, True),
            ('Only Index1 Fail',  'calc_only_idx1',   False, False, 2, False),
            ('Only Index2 Fail',  'calc_only_idx2',   False, False, 2, False),
            ('Index 1 & 2 both',  'calc_both_idx',    False, False, 2, False),
            ('Spec Fail',         'calc_spec_fail',   False, False, 2, False),

            # Group 3: RPM Fail
            ('RPM NG',            'calc_rpm_ng',      False, False, 3, True),
            ('Out of control',    'calc_out_control', False, False, 3, False),
            ('No rotate',         'calc_no_rotate',   False, False, 3, False),

            # Group 4: Others Fail
            ('Others',            'calc_others',      False, False, 4, True),
            ('PauseOrFreeRun',    'calc_pause',       False, False, 4, False),
            ('No Barcode',        'calc_no_barcode',  False, False, 4, False),
            ('Model Name',        'Model_Name',       False, True,  4, False),
        ]

        ranking_targets = ['Fail Count', 'Fail Rate', 'Noise Rate', 'RPM Fail Rate', 'Other Fail Rate']

        for label, col, is_rate, is_string, group_id, is_main in metrics_config:
            
            # Determine Base Style
            if group_id == 1:
                base_fill = fill_g1_main if is_main else fill_g1_sub
                base_font = font_g1_main if is_main else font_sub_default
            elif group_id == 2:
                base_fill = fill_g2_main if is_main else fill_g2_sub
                base_font = font_g2_main if is_main else font_sub_default
            elif group_id == 3:
                base_fill = fill_g3_main if is_main else fill_g3_sub
                base_font = font_g3_main if is_main else font_sub_default
            else: # Group 4
                base_fill = fill_g4_main if is_main else fill_g4_sub
                base_font = font_g4_main if is_main else font_sub_default

            # Metric Label Cell
            c_label = ws.cell(row=current_row, column=1, value=label)
            c_label.fill = base_fill
            c_label.font = base_font
            c_label.border = thin_border

            # Special Logic for Model Name Merge
            if label == 'Model Name':
                ws.merge_cells(start_row=current_row, start_column=2, end_row=current_row, end_column=2+len(stations))
                
                val = ",".join(line_df[col].dropna().unique().astype(str))
                c_total = ws.cell(row=current_row, column=2, value=val)
                c_total.fill = base_fill
                c_total.font = base_font
                c_total.border = thin_border
                c_total.alignment = center_align
                
                current_row += 1
                continue
            
            # Calculation
            station_values = []
            
            # Total Column
            if is_string:
                val = ",".join(line_df[col].dropna().unique().astype(str))
            elif label == 'Total Count':
                val = len(line_df)
            elif is_rate:
                total = len(line_df)
                fails = line_df[col].sum()
                val = f"{(fails/total)*100:.2f}%" if total > 0 else "0.00%"
            else:
                val = line_df[col].sum()
            
            c_total = ws.cell(row=current_row, column=2, value=val)
            c_total.fill = base_fill
            c_total.font = base_font
            c_total.border = thin_border
            c_total.alignment = center_align

            # Station Columns
            for i, station in enumerate(stations):
                st_df = line_df[line_df['Device_ID'] == station]
                
                raw_num_val = 0
                if is_string:
                    unique_names = st_df[col].dropna().unique()
                    st_val = str(unique_names[0]) if len(unique_names) > 0 else ""
                elif label == 'Total Count':
                    raw_num_val = len(st_df)
                    st_val = raw_num_val
                elif is_rate:
                    total = len(st_df)
                    fails = st_df[col].sum()
                    raw_num_val = (fails/total) if total > 0 else 0
                    st_val = f"{raw_num_val*100:.2f}%"
                else:
                    raw_num_val = st_df[col].sum()
                    st_val = raw_num_val
                
                c_st = ws.cell(row=current_row, column=i+3, value=st_val)
                c_st.fill = base_fill 
                c_st.font = base_font
                c_st.border = thin_border
                c_st.alignment = center_align
                
                station_values.append({'col_idx': i+3, 'val': raw_num_val, 'cell': c_st})

            # Ranking Logic
            if label in ranking_targets:
                unique_vals = sorted(list(set([x['val'] for x in station_values])), reverse=True)
                
                val_1st = unique_vals[0] if len(unique_vals) > 0 else None
                val_2nd = unique_vals[1] if len(unique_vals) > 1 else None
                val_3rd = unique_vals[2] if len(unique_vals) > 2 else None
                val_4rd = unique_vals[3] if len(unique_vals) > 3 else None

                for item in station_values:
                    if item['val'] == 0: continue
                        
                    if item['val'] == val_1st:
                        item['cell'].fill = rank_1_fill 
                    elif item['val'] == val_2nd:
                        item['cell'].fill = rank_2_fill 
                    elif item['val'] == val_3rd:
                        item['cell'].fill = rank_3_fill 
                    elif item['val'] == val_4rd:
                        item['cell'].fill = rank_4_fill

            current_row += 1
        
        current_row += 1 # Spacer

def run_aggregation(target_date=None):
    # ... (Keep existing run_aggregation logic) ...
    # This part remains identical to previous working versions
    # Just ensure to call create_summary_dashboard defined above
    if getattr(sys, 'frozen', False):
        base_dir = os.path.dirname(sys.executable)
    else:
        base_dir = os.path.dirname(os.path.abspath(__file__))
    
    config_path = os.path.join(base_dir, 'config.ini')

    if not os.path.exists(config_path):
        logging.error(f"Config file NOT found at: {config_path}")
        return

    config = configparser.ConfigParser()
    config.read(config_path, encoding='utf-8')

    try:
        source_dir = config['Path']['Source_Folder']
        output_base = config['Path']['Output_Folder']
        if output_base.startswith('.\\') or output_base.startswith('./'):
            output_dir = os.path.join(base_dir, output_base.replace('.\\', '').replace('./', ''))
        else:
            output_dir = output_base
    except KeyError as e:
        logging.error(f"Config file missing key: {e}")
        return
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    if target_date is None:
        from datetime import timedelta
        target_date = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
    
    logging.info(f"Starting aggregation for date: {target_date}")

    device_map = {}
    if 'Device_Mapping' in config:
        for ip, mapping in config['Device_Mapping'].items():
            try:
                line, station = mapping.split(',')
                device_map[ip.replace('.', '_')] = {'Line': line.strip(), 'Station': station.strip()}
            except ValueError:
                logging.error(f"Malformed mapping for IP {ip}: {mapping}")

    search_pattern = os.path.join(source_dir, f"{target_date}_*.txt")
    files = glob.glob(search_pattern)
    
    if not files:
        logging.warning(f"No files found for date {target_date} in {source_dir}")
        return

    all_data = []

    for file_path in files:
        filename = os.path.basename(file_path)
        match = re.match(rf"{target_date}_(.+)\.txt", filename)
        if not match:
            continue
            
        ip_key = match.group(1)
        meta = device_map.get(ip_key, {'Line': 'Unknown_Line', 'Station': f'Unknown_{ip_key}'})

        try:
            df = pd.read_csv(file_path, sep='\t', encoding='cp950', on_bad_lines='skip', index_col=False)
            df.columns = df.columns.str.strip()
            
            if 'Toral_Result' in df.columns:
                df.rename(columns={'Toral_Result':'Total_Result'}, inplace=True)
                logging.info(f"Fixed typo 'Toral_Result' in {filename}")

            if 'Total_Result' not in df.columns:
                logging.warning(f"Skipping {filename}: Missing 'Total_Result'")
                continue

            df['Line_Name'] = meta['Line']
            df['Device_ID'] = meta['Station']
            df['Source_IP'] = ip_key.replace('_', '.')
            df['Log_Date'] = target_date
            df['Total_Result'] = df['Total_Result'].astype(str)
            
            all_data.append(df)
            logging.info(f"Processed: {filename} ({len(df)} rows)")

        except UnicodeDecodeError:
            try:
                df = pd.read_csv(file_path, sep='\t', encoding='utf-8', on_bad_lines='skip', index_col=False)
                df.columns = df.columns.str.strip()
                df['Line_Name'] = meta['Line']
                df['Device_ID'] = meta['Station']
                df['Source_IP'] = ip_key.replace('_', '.')
                df['Log_Date'] = target_date
                df['Total_Result'] = df['Total_Result'].astype(str)
                all_data.append(df)
                logging.info(f"Processed (UTF-8): {filename}")
            except Exception as e2:
                logging.error(f"Failed {filename} with UTF-8: {e2}")

        except Exception as e:
            logging.error(f"Failed to read {filename}: {e}")

    if all_data:
        master_df = pd.concat(all_data, ignore_index=True)
        output_file = os.path.join(output_dir, f"Daily_Summary_{target_date}.xlsx")
        
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            master_df.to_excel(writer, sheet_name=target_date, index=False)
            create_summary_dashboard(writer, master_df, target_date)
            
        logging.info(f"Aggregation Complete. File: {output_file}")
    else:
        logging.warning("No valid data found.")

if __name__ == "__main__":
    run_aggregation()
